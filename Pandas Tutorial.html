<html>
    <head>
        <title>
            Mutyam ==> Pandas Tutorial 
        </title>
    </head>
    <body>
        <pre>
            <code>

                *** Python - Pandas Tutorial ***
                 ------------------------------ 

            ==> Pandas : is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, 
                          built on top of the python programming language. 

            
              # importing the pandas library :
                -------------------------------- 
                 import pandas as pd 
                 import numpy as np 

                 Pandas : 
                   Pandas is a powerful Python library for data manipulation and analysis. 
                   It Provides easy to use data structures and funtions to work with structures and 
                   functions to work with structure data like tabular, time series or matrix data. 

                   Pandas primarily provides two data structures : series and Dataframe 

                   Series : A one-dimensional labeled array capable of holding any data type. 
                   DataFrame : A two-dimensional labeled data structure with columns of potentially different types.
                    
              
              # Pandas - Series :
                -----------------

                    Series in pandas is a fundamental data structure that represents a one-dimensional array of indexed data. 
                    It can hold any type of data-integers, strings, floats, Python objects, etc., 
                    The series object is built on top of the Numpy array and is very similar to it but 
                    with additional capabilities like handling missing data. The indices of a pandas series are more flexible than 
                    those in a simple Numpy array. 

                    ** Creating a Series :
                    
                    s = pd.series([1,3,5,7,9])
                    print(s)

                    #output : 
                    0   1 
                    1   3 
                    2   5 
                    3   7 
                    4   9 
                    dtype : int64 

                    s = pd.series([1,3,5,7,9,"Mutyam"])
                    print(s)

                    #output : 
                    0   1 
                    1   3 
                    2   5 
                    3   7 
                    4   9 
                    5   Mutyam
                    dtype : object

                 Key attributes 
                     values : The data in the series. 
                     Index : The index (labels) of each data point. 

                ** Common Methods of Series : 

                   ==> Descriptive Statistics : 

                 ** s.describe() :  Provides a quick summary of the data. 
                  This method gives a statistical summary of the series, including count, mean, standard deviation, minimum, maximum 
                  and quartile values. 

                  # creating a series 
                    s = pd.Series([1,3,5,7,9])

                  # Descriptive Statistics 
                    print(s.describe())

                  # Output : 
                    
                     count  5.000000
                     mean   5.000000
                     std    3.162278
                     min    1.000000
                     25%    3.000000
                     50%    5.000000
                     75%    7.000000 
                     max    9.000000

                     dtype : flaoat64 

                 ** s.mean() : Computes the mean of the data. 
                 
                    # Mean of the series 
                       print(s.mean())

                    # Output : 
                       5.0 

                 ** s.std() : Computes the standard deviation 
                   
                     # Standard deviation of the series 
                       print(s.std())

                     # Output : 3.1622776601683795 

                 ** s.min() and s.max() : Computes the minimum and maximum values 

                      # Minimum and Maximum values 

                        print(s.min()) # 1
                        print(s.max()) # 9
                        
                ==> Data Manipulation : 

                  ** s.map(func) : Applies a function to each element in the series. 

                     # Mapping function to double the values. 
                     doubled = s.map(lambda x : x * 2)
                     print(doubled) 

                     # Output : 
                     0   2 
                     1   16 
                     2   10 
                     3   14
                     4   18
                     dtype : int64 

                  ** s.apply(func) : similar to map, but more flexible. (can be used data frames as well, where as map is only for Series). 

                     # Applying a function to calculate square root. 

                       sqrt = s.apply(lambda x: x ** 0.5)

                     # Output : 

                       0   1.000000
                       1   1.732051
                       2   2.236068
                       3   2.645751
                       4   3.000000 
                       dtype : float64
                       
                  ** s.sort_values(): Sorts the Series 

                      # Sorting the series 
                       
                       s = pd.series([7,1,5,3,9])
                       sorted_s = s.sort_values()
                       print(sorted_s)

                       # Output : 

                       1   1 
                       3   3
                       2   5
                       0   7
                       4   9 
                       dtype : int64 

                  ** s.drop(labels) : Drops specified lables from the series. 

                      # Dropping the first element # here it create a new series and stored in dropped variable it won't effect original series

                         dropped = s.drop(0)
                         print(dropped)
                         print(s)
                      # Output : 

                       1   3
                       2   5
                       3   7 
                       4   9
                       dtype : int64 

                       # Dropping the first element with inplace = True 

                         s.drop(0, inplace = True) # here it effects original series s 
                         print(s)

                      # Output : 

                       1   3
                       2   5
                       3   7 
                       4   9
                       dtype : int64

                ==> Handling Missing Data : 

                  ** s.isnull() : Checks for missing values, returns a Series of booleans. 

                      # checking for missing values 
                         print(s.isnull())

                      # Output : 
                       
                        0  False 
                        1  False 
                        2  False 
                        3  False 
                        4  False 
                        dtype : bool 

                  ** s.notnull() : Opposite of isnull()      

                      # Checking for non-null values 
                      print(s.notnull())

                      0   True 
                      1   True 
                      2   True 
                      3   True 
                      4   True 
                      dtype : bool 

                  ** s.fillna(value) :  Fills missing values with a specified value 

                     # Create a Series with missing values 
                       
                        s = pd.Series([1,2,np.nan,4,np.nan])

                     # Print the Series 
                        
                        print(s)

                     # Output : 

                       0   1.0
                       1   2.0
                       2   NaN
                       3   4.0
                       4   NaN

                     # Filling missing values with 0 

                     filled = s.fillna(0)
                     print(filled)

                     # Output : 

                      0   1.0
                      1   2.0
                      2   9.0
                      3   4.0
                      4   9.0
                      dtype : float64 

                  ** s.dropna() : Drops all rows that contain missing values. 

                     # Creating a series with missing values 
                       s_with_missing = pd.Series([1,2, None,4,5])

                     # Dropping missing values 
                       dropped_missing = s_with_missing.dropna()
                       print(dropped_missing)

                     # Output : 

                       0   1.0
                       1   2.0
                       3   4.0
                       4   5.0 

                ==> Indexing, Slicing and Filtering : 
                
                    ** s.iloc[] : Purely integer-location based indexing 

                    # Indexing by position 
                       s = pd.Series([1,3,5,7,9])
                       print(s.iloc[0]) # First element 
                       print(s.iloc[-1]) # Last element 

                    # Output : 
                       1 
                       9 

                    ** s.loc[] : Label-based indexing 
                        
                     # Indexing by label 
                       print(s.loc[0]) # First element 
                       print(s.loc[4]) # Last element 

                     # Output : 
                        1 
                        9 

                    # Create a Series : 

                      s = pd.series([10,20,30,40], index = ['a','b','c','d'])
                      print(s)

                    # Accessig elements using iloc 
                      print(s.iloc[0]) # Access the first element 
                      print(s.iloc[1:3]) # Access elements at position 1 and 2 (exclusive of 3)

                    # Accessing elements using loc 
                      print(s.loc['a']) # Access the element with index label 'a'
                      print(s.loc['b':'c']) # Access elements with index labels 'b' and 'c'

                    # Output : 
                       a   10
                       b   20
                       c   30
                       d   40 
                       dtype : int64 

                       10
                       b   20
                       c   30
                       dtype : int64

                       10
                       b   20
                       c   30 
                       dtype : int64 

                   ** Filtering 
                     ** s[s > n] : Filters and returns elements greater than n. 

                     # Filtering elements greater than 5 
                        filtered = s[s > 5]
                        print(filtered)

                     # Output : 
                         3    7
                         4    9 
                         dtype : int64 

                ==> Aggregation : 

                     ** s.sum() : Sums up the values. 

                         # Sum of the series 
                           print(s.sum())

                         #output : 25

                      ** s.cumsum() : Cumulative Sum 

                           # Cumulative sum of the series 
                           print(s)
                           print(s.cumsum())

                           #output : 

                           0    1
                           1    3
                           2    5
                           3    7 
                           4    9 
                           dtype : int64 
                           0    1
                           1    4
                           2    9
                           3    16
                           4    25 
                           dtype : int64 

                      ** s.aggrgate(func): Aggregates using one or more operations. 

                         # Aggregating using multiple operations 
                         aggregated = s.aggregate(['sum','mean','std'])
                         print(aggregated)

                         # Output : 

                         sum   25.000000
                         mean  15.000000
                         std   3.162278
                         dtype: float64 

                  ==> Creating DataFrame
                      ------------------- 
                      
                         data = {
                              'Name' : ['Mutyam', 'Bhargav','Reddy', 'Sanjai', 'Srinath'],
                              'Role' : ['Founder', 'Growth Manager', 'Community Mangaer', 'Community Manager', 'Course Designer'],
                              'Phone Number' : ['111-111-111','222-222-222','333-333-333','444-444-444','555-555-555'],
                              'Email' : ['Mutyam@Dit.ac.in','Bhargav@Dit.ac.in','Reddy@Dit.ac.in','Sanjai@Dit.ac.in','Srinath@Dit.ac.in'],
                              'Address' : ['Cham', 'regensburg', 'Cham','Nuremberg','Erlangen']
                              'BloodGroup' : ['A+','B+', 'AB+','O+', 'O-']


                         }

                         # Create DataFrame 
                         team_dit_df = pd.DataFrame(data)

                         # Display DataFrame 
                         team_dit_df.head()

                         team_dit_df.head(10) # Display first 10 members
                         
                         team_dit_df # Display all the data 

                         # Output : 

                              Name |  Role | Phone Number | Email | Address | BloodGroup 

                          1. 
                          2.
                          3.
                          4.
                          5.
                
               ==> Merging Data Frames 

                    # Team roles data 

                     roles_data = {
                            'Name' : ['Mutyam', 'Bhargav', 'Reddy', 'Sanjai', 'Srinath'],
                            'Role' : ['Founder', 'Growth Manager', 'Community Mangaer', 'Community Manager', 'Course Designer'],

                     }

                     roles_df = pd.DataFrame(roles_data)

                    # Contact information data 

                    contact_data = {
                              'Name' : ['Mutyam', 'Bhargav', 'Reddy', 'Sanjai', 'Srinath'],
                              'Phone Number' : ['111-111-111','222-222-222','333-333-333','444-444-444','555-555-555'],
                              'Email' : ['Mutyam@Dit.ac.in','Bhargav@Dit.ac.in','Reddy@Dit.ac.in','Sanjai@Dit.ac.in','Srinath@Dit.ac.in'],
                        
                    }

                    contact_data = pd.DataFrame(contact_data)

                    merge_df = pd.merge(roles_df, contact_df, on = 'Name')

             ==> Importing Dataset : 

                    Importing datasets into pandas is straightforward and pandas supports various file formats like 'csv','xlsx','json','sql',etc., 

                    df = pd.read_csv('filmtv_movies.csv')

                    # Display the first few rows of the DataFrame to understand its structure and contents 

                    df.head()


              ==> Pandas - DataFrame : 

                    Properties of DataFrame : 

                  ** df.head(n) : The df.head(n) method is used to view the first n rows of the DataFrame. 
                                  This is particularly useful for getting a quick snapshot of the 
                                  data, especially to understand the structure and the types of data contained in each column, 
                                  If you don't specify n, the default number of rows displayed is 5. 

                                  df.head(10) # Displays the first 10 rows of the DataFrame 

                  ** df.tail(n) : The df.tail(n) method is similar tot df.head(n) but for the end of the DataFrame. 
                                  It returns the last n rows. This is useful to see the most recent or the last few entries in your data, 
                                  depending on the ordering of your dataset. Like df.head(n), the default value of n is 5 if it isn't specified 

                                  df.tail(10) # Displays the last 10 rows of the DataFrame. 

                  ** df.shape : The df.shape attribute of a DataFrame returns a tuple representing the dimensionality of the DataFrame. 
                                The first element of the tuple is the number of rows, and the second is the number of columns. 
                                This is useful when you need to know how large the dataset is, such as when you are preprocessing data or ensuring that data manipulations have e
                                executed correctly. 

                                  df.shape # Output : (number of rows, number of column)

                  ** df.columns : The df.columns attribute returns an index object containing the column labels of the DataFrame. 
                                  Knowing the column names id essential for accessing specific data in the DataFrame, performing analyses, and for data manipulation tasks like sorting, 
                                  filtering, or applying functions to certail columns. 

                                  df.columns # List all the column names in the DataFrame 

                  ** Inspecting Data Types : Each Column in a DatFrame has a Specific data type. Understanding these types is crucial for proper data manipulation 

                                  # Display the data types of each column 
                                  df.dtypes 

                  ** Summary Statistics :  For numerical data, it's useful to get a sense of their central tendency and spread 
                                            
                                   # Display summary Statistics for numerical columns 
                                     df.describe()

            ==> Accessing and Filtering : 

                   
                   ** df.loc : The df.loc method is used for label-based indexing, meaning you can access rows and columns using their labels (i.e index names and column names).
                               It allows for selecting a subset of rows and columns from a DataFrame with powerful and flexible slicing, indexing, and filtering options. 
                               
                               # Selecting all rows and a specific column by label 
                               titles = df.loc[:,'title']

                               # Selecting a range of rows and multiple columns by labels 
                                subset = df.loc[10:20, ['title','year','genre']] #  it will print from 10 to 20 rows
                                subset

                               # Conditional Selection using a boolean array 
                                 dramas = df.loc[df['genre'] == 'Drama']

                               # multiple_condition = df.loc[(df['genre']=='Drama') & (df['avg_vote']>7.0)]
                                  multiple_condition

                    ** df.iloc : While df.iloc uses labels for indexing, df.iloc allows for integer-based indexing. 
                                 You use df.iloc to access rows and columns by their integer positions, which makes it useful 
                                 when you need to access data by its position in the DataFrame.

                               # Selecting a single row from the DataFrame 

                                   single_row = df.iloc[0]
                                   single_row

                               # Selecting a specific row and columns by integer indices.
                                   
                                   specific_data = df.iloc[10, [1,2,3]] # row at index 10 and column at  
                                   specific_data 

                               # Slicing to get multiple rows and columns 
                                 
                                   multi_slice = df.iloc[10:15,0:4] # Rows 10 to 14 and columns 0 to 3 
                                   multi_slice

                    ** df.at : df.at is designed to access a single value for a row / column label pair. 
                               It is very similar to df.loc for accessing scalar values but is optimized for faster access when you only 
                               need to get or set a single value in DataFrame. 

                               # Access a specific single value using row label and column name 
                                 
                                   title_of_first_movie = df.at[0, 'title']
                                   title_of_first_movie

                    ** Filtering Based on Criteria : Filtering data based on specific criteria is a common operation

                           #   Filter movies released after 2010 
                              recent_movies = df[df['year']>2010]
                              recent_movies

                           #   Movies with a high public vote and specific genre 
                               highly_rated_thrillers = df[(df['public_vote'] >= 8) & (df['genre'] == 'Thriller')]
                               highly_rated_thrillers

                           #   Movies from a specific country 
                               us_movies = df[df['country'] == 'United States']
                               us_movies

                  ==> Updating Rows and Columns
                  
                           ** df.drop : The drop() method in pandas is used to remove rows and columns from a DataFrame. 
                                        It primary purpose is to drop specified labels from rows or columns. 

                                parameters : 

                                labels : The row or column labels to drop 

                                axis : Specifies whether the labels refer to rows (axis = 0) or columns (axis = 1). By default, it's 0 (row)
                                
                                index or column :  An alternative way to specify the lables to drop, instead of using the labels paramter. 
                                                   It is equivalent to specifying axis = 0 (for index) or axis = 1 (for columns). 

                                inplace : If True, the operation is done in place, meaning it modifies the DataFrame directly and returns None. 
                                          If False or not specified, it returns a new DataFrame with the specified labels dropped. 

                                # df.drop(labels = 'title', axis = 1)

                                

                            
                              
                        

                                   

                        

                       




                     











                   







            ==> Pandas Library : 
             
                 Useful for Data Processing and Analysis : 

                 Pandas Data Frame : 
                 ------------------ 

                Pandas Dataframe is two-dimensional tabular datastructure with labeled axes (rows and columns)




                  






            </code>
        </pre>
    </body>
</html>